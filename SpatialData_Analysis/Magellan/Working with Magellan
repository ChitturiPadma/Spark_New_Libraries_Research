This is a collection of libraries and API built on top of Apache Spark to perform geospatial analytics on big data sets.
It internally leverages Spark Dataframes, Catalyst optimizer, Tungsten and indexing mechanisms to perfrom the spatial 
operations.

Spatial JOINs:
Let's say we have have point data set and polygon dataset and we need to determine if the points lie within the polygon

Time take for the JOIN operation depends on the size of the polygon dataset (i.e proportional to the number of polygons 
in the dataset). In case og naive JOIN, look at the bounding box of each polygon to decide whether a particular point has a 
probability of being inside. If its within the bounding box, perform an expensive point in polygon test and determine 
if its actually inside the polygon.
 
Using Magellan, Spatial Join Rule can be injected into Catalyst, which builds spatial indices on the fly for both the 
point and polygon datasets. Hence join uses these indices and avoid expensive Cartesian Join.

Point in Polygon Test: Ray Casting algorithm.
https://en.wikipedia.org/wiki/Point_in_polygon
For a polygon with p edges, time complexity of the algorithm is O(p).

For a polygon we can compute the bounding box (smallest axis parallel rectangle) that encloses the polygon. Post this, to
check if a point lies within the polygon, first check if the point is within the bounding box. If its not then the point 
cannot be iwthin the polygon.
In case if the point is within the bounding box, we perform the expensive operation of point in polygon test. 

Geospatial Indices:
What if set of polygons surrounded by a large boundibg box ?

Sub-divide the bounding box into small cells. For each cell, determine if the cell is either within or oeverlaps or is disjoint
from the polygon. 

Now for each point, find if it falls inside a cell. After determining the cell, prune all the polygons that do not 
contain/overlap that cell.

For polygons that contain the cell -> point also lies within the polygon.
The expensive operation of point in polygon test is performed when there are cells that overlap/contained in the 
polygon.

Methodologies for contructing small cells inside a large bounding box ->  Space filling curves and Z-order curves
https://en.wikipedia.org/wiki/Space-filling_curve
https://en.wikipedia.org/wiki/Z-order_curve

Support for the following spatial formats of the data -
1. ESRI
2. GeoJSON
3. OSM-XML
4. WKT

Spatial indexes support ZOrderCurves. When given a column of shapes, we can index the shapes to a given precision, 
using a geohash indexer. Usage of geohash indexer produces list of ZOrder Curves which together cover the polygon.

The spatial joins are by default treated as cratesian joins. To avoid this, add a spatial join rule by using the below
line of code -
magellan.Utils.injectRules(spark)

Also, during the join provide precision which automatically uses indexes to speed up the join.



